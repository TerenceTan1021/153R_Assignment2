{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eecebc3b",
   "metadata": {},
   "source": [
    "# Chord → Melody Mini‑Pipeline\n",
    "\n",
    "**Assumptions**\n",
    "* You have pre‑tokenised chord / melody pairs stored as `.npz` files under `cached_tokens/`, each containing:\n",
    "  * `arr_0` – chord token sequence (1‑D uint16)\n",
    "  * `arr_1` – melody token sequence (1‑D uint16)\n",
    "\n",
    "If `cached_tokens/` is empty the notebook will **fabricate a tiny dummy dataset** so you can still run end‑to‑end, but training quality will be useless.  Replace with real data for meaningful results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283afbc",
   "metadata": {},
   "source": [
    "## 0  Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39155956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyfluidsynth in /Users/oscarodonnell/env/lib/python3.12/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /Users/oscarodonnell/env/lib/python3.12/site-packages (from pyfluidsynth) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet torch tqdm numpy pretty_midi\n",
    "!pip install pyfluidsynth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ef030",
   "metadata": {},
   "source": [
    "## 1  Imports, constants, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d2cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2301 npz pairs found   vocab=196\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pretty_midi as pm\n",
    "\n",
    "# ------------ constants ------------\n",
    "PAD     = 0                 # also used as <bos>/<eos> for simplicity\n",
    "BATCH   = 64\n",
    "EPOCHS  = 5\n",
    "D_MODEL = 256\n",
    "\n",
    "CACHE_DIR = Path('cached_tokens')\n",
    "CACHE_DIR.mkdir(exist_ok=True)   # ensure folder exists\n",
    "files = sorted(CACHE_DIR.glob('*.npz'))\n",
    "\n",
    "# ------------ fabricate dummy data if none present ------------\n",
    "if not files:\n",
    "    print('cached_tokens is empty – creating 512 fake examples for demo…')\n",
    "    V = 60       # token vocab size (C majors etc.)\n",
    "    for i in range(512):\n",
    "        L = np.random.randint(16, 64)\n",
    "        chords  = np.random.randint(1, V//2,  size=L,  dtype=np.uint16)\n",
    "        melody  = np.random.randint(V//2, V,  size=L,  dtype=np.uint16)\n",
    "        np.savez_compressed(CACHE_DIR/f'dummy_{i}.npz', chords, melody)\n",
    "    files = sorted(CACHE_DIR.glob('*.npz'))\n",
    "\n",
    "# derive vocab size from first file\n",
    "with np.load(files[0]) as z:\n",
    "    VOCAB = int(max(z['arr_0'].max(), z['arr_1'].max())) + 1\n",
    "print(f'{len(files)} npz pairs found   vocab={VOCAB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc14ae",
   "metadata": {},
   "source": [
    "## 2  Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "307baf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader ready  batches per epoch = 144\n"
     ]
    }
   ],
   "source": [
    "class Tokset(Dataset):\n",
    "    def __init__(self, file_list): self.fs = file_list\n",
    "    def __len__(self): return len(self.fs)\n",
    "    def __getitem__(self, idx):\n",
    "        with np.load(self.fs[idx]) as d:\n",
    "            x = torch.from_numpy(d['arr_0'].astype(np.int32))   # ← cast\n",
    "            y = torch.from_numpy(d['arr_1'].astype(np.int32))\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# keep only first 512 frames – good for a baseline\n",
    "MAXLEN = 256\n",
    "BATCH = 16\n",
    "\n",
    "def collate(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    xs = nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=PAD)[:, :MAXLEN]\n",
    "    ys = nn.utils.rnn.pad_sequence(ys, batch_first=True, padding_value=PAD)[:, :MAXLEN]\n",
    "    return xs, ys[:, :-1], ys[:, 1:]\n",
    "\n",
    "\n",
    "loader = DataLoader(train_ds, batch_size=32, num_workers=4, collate_fn=collate)\n",
    "\n",
    "\n",
    "train_ds = Tokset(files)\n",
    "loader   = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n",
    "                      collate_fn=collate, num_workers=0)\n",
    "print(f'Dataloader ready  batches per epoch = {len(loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3cd5d",
   "metadata": {},
   "source": [
    "## 3  Tiny Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90f3134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256])\n"
     ]
    }
   ],
   "source": [
    "class ChordMelody(nn.Module):\n",
    "    def __init__(self, vocab, d=D_MODEL):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Embedding(vocab, d, padding_idx=PAD)\n",
    "        self.dec = nn.Embedding(vocab, d, padding_idx=PAD)\n",
    "        self.tf  = nn.Transformer(d_model=d, nhead=4,\n",
    "                                  num_encoder_layers=3, num_decoder_layers=3,\n",
    "                                  batch_first=True)\n",
    "        self.out = nn.Linear(d, vocab)\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = src.eq(PAD); tgt_mask = tgt.eq(PAD)\n",
    "        y = self.tf(self.enc(src), self.dec(tgt),\n",
    "                    src_key_padding_mask=src_mask,\n",
    "                    tgt_key_padding_mask=tgt_mask)\n",
    "        return self.out(y)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = ChordMelody(VOCAB).to(device)\n",
    "optim  = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "lossF  = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "next(iter(loader))             # time this — should be <1 s\n",
    "print(src.shape)               # from training loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83df2f3",
   "metadata": {},
   "source": [
    "## 4  Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1b61afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/144 [00:26<?, ?it/s]\n",
      "100%|██████████| 144/144 [05:33<00:00,  2.32s/it], loss=1.62]\n",
      "Epoch 1/5:   0%|          | 0/144 [05:33<?, ?it/s, loss=1.62]\n",
      "100%|██████████| 144/144 [05:52<00:00,  2.45s/it]\n",
      "Epoch 2/5:   0%|          | 0/144 [05:52<?, ?it/s, loss=1.61]\n",
      "100%|██████████| 144/144 [05:43<00:00,  2.39s/it], loss=1.85]\n",
      "Epoch 3/5:   0%|          | 0/144 [05:43<?, ?it/s, loss=1.85]\n",
      "100%|██████████| 144/144 [05:39<00:00,  2.36s/it]\n",
      "Epoch 4/5:   0%|          | 0/144 [05:39<?, ?it/s, loss=1.44]\n",
      "100%|██████████| 144/144 [05:47<00:00,  2.41s/it], loss=2.18]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(EPOCHS):\n",
    "    model.train()\n",
    "    pbar = tqdm(loader, desc=f'Epoch {ep+1}/{EPOCHS}')\n",
    "    for src, tgt_in, tgt_out in tqdm(loader):\n",
    "        src, tgt_in, tgt_out = [t.to(device).long()   # ← cast to int64\n",
    "                                for t in (src, tgt_in, tgt_out)]\n",
    "\n",
    "        optim.zero_grad()\n",
    "        logits = model(src, tgt_in)\n",
    "        loss   = lossF(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt_out.reshape(-1)\n",
    "        )\n",
    "        loss.backward(); optim.step()\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16490a89",
   "metadata": {},
   "source": [
    "## 5  Generate a melody for one chord sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abe7d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet pyfluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "302e3a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ wrote generated_melody.mid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='generated_melody.mid' target='_blank'>generated_melody.mid</a><br>"
      ],
      "text/plain": [
       "/Users/oscarodonnell/Desktop/CSE153/a2t2/generated_melody.mid"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pretty_midi as pm, torch, numpy as np\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# --- 1. Generate melody tokens (greedy) -----------------------\n",
    "model.eval()\n",
    "src, _ = train_ds[0]                        # chord sequence only\n",
    "src = src.unsqueeze(0).to(device)\n",
    "tgt = torch.tensor([[PAD]], device=device)  # <bos>\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(src.size(1)):            # limit to chord length\n",
    "        logits = model(src, tgt)\n",
    "        next_tok = logits[:, -1].argmax(-1, keepdim=True)\n",
    "        tgt = torch.cat([tgt, next_tok], 1)\n",
    "        if next_tok.item() == PAD: break\n",
    "\n",
    "mel_tokens = tgt.squeeze(0).cpu().tolist()[1:-1]\n",
    "\n",
    "# --- 2. Decode tokens → PrettyMIDI ----------------------------\n",
    "hop = 0.5\n",
    "midi = pm.PrettyMIDI()\n",
    "inst = pm.Instrument(program=0, name=\"melody\")\n",
    "time = 0.0\n",
    "for tok in mel_tokens:\n",
    "    if tok != PAD:\n",
    "        inst.notes.append(pm.Note(velocity=90, pitch=int(tok),\n",
    "                                  start=time, end=time + hop * 0.9))\n",
    "    time += hop\n",
    "midi.instruments.append(inst)\n",
    "midi_path = \"generated_melody.mid\"\n",
    "midi.write(midi_path)\n",
    "\n",
    "# --- 3. Provide a download link -------------------------------\n",
    "print(\"✓ wrote\", midi_path)\n",
    "FileLink(midi_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
